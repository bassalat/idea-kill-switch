# CLAUDE.md - AI-Powered Kill Switch Project Guide

## Project Overview

This is an AI-powered business idea validation tool built with Streamlit, Claude API, and Serper.dev. The application helps entrepreneurs quickly validate business ideas through automated research and analysis, providing "kill or continue" decisions at each validation stage.

## Project Structure

```
kill_switch/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pain_research.py   # Task 1: Pain Research Module
â”‚   â”œâ”€â”€ market_analysis.py # Task 2: Market Analysis Module
â”‚   â”œâ”€â”€ content_gen.py     # Task 3: Content Generation Module
â”‚   â””â”€â”€ survey_analysis.py # Task 4: Survey Analysis Module
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ claude_client.py   # Claude API wrapper
â”‚   â”œâ”€â”€ serper_client.py   # Serper.dev API wrapper
â”‚   â”œâ”€â”€ validators.py      # Input validation and sanitization
â”‚   â””â”€â”€ exporters.py       # Report export utilities
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py        # Configuration management
â”‚   â””â”€â”€ prompts.py         # AI prompt templates
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ styles.css         # Custom styling
â”‚   â””â”€â”€ logo.png           # Branding assets
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_modules.py
â”‚   â””â”€â”€ test_utils.py
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                  # Environment variables (already configured)
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml       # Streamlit configuration
â”œâ”€â”€ README.md             # User documentation
â”œâ”€â”€ PRD.md                # Product Requirements Document
â”œâ”€â”€ CLAUDE.md             # This file
â””â”€â”€ task.md               # Original LinkedIn post content
```

## Key Implementation Guidelines

### 1. API Integration

**Claude API Setup:**
```python
# Use Anthropic's official Python SDK
# Model: claude-sonnet-4-20250514 (Claude Sonnet 4 - exceptional reasoning)
# Implement retry logic and error handling
# Cache responses where appropriate
```

**Serper.dev Setup:**
```python
# Use requests library for API calls
# Implement pagination for large result sets
# Filter results by date (last 6 months)
# Parse and structure search results
```

### 2. Module Implementation

**Pain Research Module (modules/pain_research.py):**
- Search for complaints on Reddit, forums, review sites
- Extract and analyze complaint patterns
- Calculate pain score (1-10)
- Return structured findings with quotes and links

**Market Analysis Module (modules/market_analysis.py):**
- Search for competitors and pricing information
- Analyze market size and revenue potential
- Identify gaps in current solutions
- Generate competitor matrix

**Content Generation Module (modules/content_gen.py):**
- Generate landing page copy based on findings
- Create platform-specific social media posts
- Include conversion tracking recommendations
- Provide A/B testing suggestions

**Survey Analysis Module (modules/survey_analysis.py):**
- Generate survey questions based on validation results
- Process and analyze survey responses
- Calculate average willingness to pay
- Provide pricing recommendations

### 3. Streamlit UI Flow

**Main App Structure:**
```python
# Use st.session_state for multi-step process
# Implement progress tracking
# Show real-time updates during API calls
# Clear visual indicators for kill/continue decisions
```

**Page Layout:**
1. **Welcome Screen:** Brief explanation
2. **Idea Input:** Problem description and target audience
3. **Validation Process:** Sequential modules with progress bar
4. **Results Dashboard:** Summary and detailed findings
5. **Export Options:** PDF and CSV download

### 4. Error Handling

- Graceful API failure recovery
- Clear user-facing error messages
- Fallback options for failed searches
- Input validation and sanitization
- Rate limiting compliance

### 5. Performance Optimization

- Concurrent API calls where possible
- Response caching strategy
- Efficient prompt engineering
- Minimal API token usage
- Progress indicators for long operations

## Development Workflow

### Environment Setup:

**IMPORTANT:** Always use the `venv_killswitch` conda environment when working with Python in this project.

**Note:** This project uses Miniconda installed at `/Users/bassalat/opt/miniconda3/`

```bash
# First, source the conda initialization script
source /Users/bassalat/opt/miniconda3/etc/profile.d/conda.sh

# Create conda environment if it doesn't exist
conda create -n venv_killswitch python=3.10 -y

# Activate the environment
conda activate venv_killswitch

# Install dependencies
pip install -r requirements.txt

# Note: .env file with API keys for Claude and Serper.dev is already configured
```

**For all Python commands in this project:**
```bash
# Always activate the environment first
source /Users/bassalat/opt/miniconda3/etc/profile.d/conda.sh && conda activate venv_killswitch

# Then run your Python commands
python app.py
pytest tests/
```

### Running the Application:
```bash
# Activate the conda environment
source /Users/bassalat/opt/miniconda3/etc/profile.d/conda.sh && conda activate venv_killswitch

# Run the Streamlit app
streamlit run app.py
```

### Testing:
```bash
# Activate the conda environment
source /Users/bassalat/opt/miniconda3/etc/profile.d/conda.sh && conda activate venv_killswitch

# Run tests
pytest tests/

# Run specific test file
pytest tests/test_modules.py -v

# Run with coverage
pytest tests/ --cov=. --cov-report=html
```

## Important Considerations

### Security:
- Never commit API keys (already configured in .env)
- Sanitize all user inputs
- Use environment variables for sensitive data
- Implement rate limiting

### User Experience:
- Keep UI simple and intuitive
- Provide clear progress indicators
- Show intermediate results
- Offer helpful error messages

### Cost Management:
- Monitor API usage
- Implement caching
- Set user limits if needed
- Optimize prompt lengths

## Validation Criteria

### Pain Research - Three-Tier System:

1. **ðŸŸ¢ Easy (Market Exists):** 
   - Weighted complaints â‰¥ 20
   - Pain score â‰¥ 5/10
   - Any quality level

2. **ðŸŸ¡ Medium (Strong Opportunity) - Default:**
   - Weighted complaints â‰¥ 40
   - Pain score â‰¥ 6/10
   - Quality rating: Medium or higher

3. **ðŸ”´ Difficult (Exceptional Problem):**
   - Weighted complaints â‰¥ 60
   - Pain score â‰¥ 8/10
   - Quality rating: High
   - Urgency â‰¥ 40%
   - Emotional intensity â‰¥ 30%

### Other Module Criteria:

1. **Market Analysis:** < 3 competitors charging $50+ = KILL
2. **Content Testing:** < 2% predicted conversion rate = KILL
3. **Survey Analysis:** Average WTP < $50/month = KILL

## Future Enhancements

- Save and compare multiple validations
- Industry-specific templates
- Integration with other tools (Google Analytics, etc.)
- Machine learning on validation patterns
- Team collaboration features

## Debugging Tips

- Use Streamlit's debug mode
- Log API requests and responses
- Test with mock data first
- Monitor token usage
- Check rate limits regularly

## Resources

- [Streamlit Documentation](https://docs.streamlit.io)
- [Claude API Documentation](https://docs.anthropic.com)
- [Serper.dev Documentation](https://serper.dev/docs)

## Commands to Run

```bash
# Always activate the environment first
source /Users/bassalat/opt/miniconda3/etc/profile.d/conda.sh && conda activate venv_killswitch

# Linting
ruff check .

# Type checking (if using mypy)
mypy .

# Format code
black .

# Run the application
streamlit run app.py

# Run tests
pytest tests/ -v
```